{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Database\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citi Bike provides a valuable tranportation service to people who live in or travel to NYC. It has an [open Citi Bike database](https://ride.citibikenyc.com/system-data) and it's free for the public to [download](https://s3.amazonaws.com/tripdata/index.html). In this notebook, we will build a SQL database populated with the data. Since the data format was changed in Feburary 2021, we'll focus on the NYC's trip data before 2021.\n",
    "  \n",
    "In this notebook, we will build up a webscraper to pull all the necessary data. After downloading the data, we will merge files and import the data into a PostgreSQL database. \n",
    "  \n",
    "⚠️A new data format of Citi Bike trip data has been used from February 2021.  \n",
    "⚠️If you encounter issues when you run the codes. Please go and check [Issues](https://github.com/Fitzmon/CitiBike_Analysis/issues?q=is%3Aissue+is%3Aclosed) page.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Refenrence: \n",
    "- [Building a Citibike Database with Python](https://medium.com/@fausto.manon/building-a-citibike-database-with-python-9849a59fb90c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [01. Importing Libraries](#01.-Importing-Libraries)\n",
    "- [02. Data Preparation](#02.-Data-Preparation)\n",
    "- [03. Building a PostgreSQL Database](#03.-Building-a-PostgreSQL-Database)\n",
    "- [04. Unsettled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 01. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping libraries\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Downloading, moving and unzipping files\n",
    "import webbrowser\n",
    "from time import sleep\n",
    "import shutil \n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# DataFrame exploration and manipulation\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# PostgreSQL interaction\n",
    "import psycopg2\n",
    "import linecache\n",
    "from psycopg2 import sql\n",
    "from psycopg2 import Error\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 02. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3.amazonaws.com/tripdata/'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = soup.find_all('Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the step below, we're going to retreive all of the zip files from the site. As Citi Bike also extends to Jersey City and Hoboken in New Jersey, we will filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate empty list\n",
    "zip_files = []\n",
    "filter_files = []\n",
    "\n",
    "# Populate list with zip file names\n",
    "for file in range(len(data_files)-1):\n",
    "    zip_files.append(data_files[file].get_text())\n",
    "\n",
    "# Filter list with date file names\n",
    "for file in zip_files:\n",
    "    if 'JC' in file:\n",
    "        continue\n",
    "    elif '2021' in file: \n",
    "        continue\n",
    "    elif '2022' in file:\n",
    "        continue\n",
    "    else:            \n",
    "        filter_files.append(file)    \n",
    "\n",
    "# Sort the list\n",
    "filter_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `webbrowser.open_new(url)` function will open url using the default browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download New York City zip files\n",
    "for file in filter_files: \n",
    "    webbrowser.open_new(url + file)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading all of respective .zip files, we will unzip them and then relocate them from the default download folder to the project folder.  \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Here I suggest that you <b>change the dafult download location</b> (usually \"C:\\Users\\your_name\\Downloads\") to the project folder from the Settings page in the browser.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_loc = 'C:/Users/Hui/Downloads/'\n",
    "project_loc = 'C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/'\n",
    "\n",
    "#-----OPTION 1: Save in project folder-----\n",
    "# Unzip files and clean up data folder\n",
    "for file in filter_files:\n",
    "    file_name = project_loc + file\n",
    "    with ZipFile(file_name) as zip_ref:\n",
    "        zip_ref.extractall(project_loc)\n",
    "    os.remove(file_name)\n",
    "\n",
    "    \n",
    "#-----OPTION 2: Save in default folder-----\n",
    "# Unzip files and clean up data folder\n",
    "# for item in os.listdir(down_loc):\n",
    "#     if item.endswith('.zip'):\n",
    "#         file_name = down_loc + item\n",
    "#         with ZipFile(file_name) as zip_ref:\n",
    "#             zip_ref.extractall(down_loc)\n",
    "#         os.remove(file_name)\n",
    "        \n",
    "# Move from Download folder to data folder\n",
    "# for item in os.listdir(down_loc):\n",
    "#     shutil.move(down_loc + item, project_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the data type\n",
    "files = os.listdir('C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/2013/')\n",
    "\n",
    "for csv in files:\n",
    "    df = pd.read_csv(f'C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/2013/{csv}')\n",
    "    df = df.rename(columns=({'trip_duration':'tripduration',\n",
    "                             'start_time':'starttime',\n",
    "                             'stop_time':'stoptime',\n",
    "                             'start_station_id':'start station id',\n",
    "                             'start_station_name':'start station name',\n",
    "                             'start_station_latitude':'start station latitude',\n",
    "                             'start_station_longitude':'start station longitude',\n",
    "                             'end_station_id':'end station id',\n",
    "                             'end_station_name':'end station name',\n",
    "                             'end_station_latitude':'end station latitude',\n",
    "                             'end_station_longitude':'end station longitude',\n",
    "                             'bike_id':'bikeid',\n",
    "                             'user_type':'usertype',\n",
    "                             'birth_year':'birth year',\n",
    "                             'gender':'gender'}))\n",
    "    df.to_csv(f'C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/2013/{csv}', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_files = sorted(glob('C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/2013/*.csv'))\n",
    "ny_trip_data = pd.concat((pd.read_csv(file) for file in ny_files), ignore_index = True)\n",
    "ny_trip_data.to_csv('C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/2013/ny_trip_data_2013.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6697019 entries, 0 to 6697018\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   tripduration             int64  \n",
      " 1   starttime                object \n",
      " 2   stoptime                 object \n",
      " 3   start station id         int64  \n",
      " 4   start station name       object \n",
      " 5   start station latitude   float64\n",
      " 6   start station longitude  float64\n",
      " 7   end station id           int64  \n",
      " 8   end station name         object \n",
      " 9   end station latitude     float64\n",
      " 10  end station longitude    float64\n",
      " 11  bikeid                   int64  \n",
      " 12  usertype                 object \n",
      " 13  birth year               object \n",
      " 14  gender                   int64  \n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 766.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ny_trip_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 03. Building a PostgreSQL Database\n",
    "Please establish a connection with PostgreSQL and create a new database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateDatabase",
     "evalue": "database \"citibike_data\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateDatabase\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35536/679572766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create DB in PostgreSQL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mcreate_database\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"CREATE DATABASE {db_name};\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_database\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Database created successfully in PostgreSQL\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateDatabase\u001b[0m: database \"citibike_data\" already exists\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\"user=postgres password='password'\");\n",
    "conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT);\n",
    "\n",
    "# Obtain in a DB Cursor\n",
    "cursor = conn.cursor();\n",
    "db_name = \"citibike_data\"\n",
    "\n",
    "# Create DB in PostgreSQL\n",
    "create_database = f\"CREATE DATABASE {db_name};\"\n",
    "cursor.execute(create_database);\n",
    "print(\"Database created successfully in PostgreSQL\")\n",
    "\n",
    "# Closing PostgreSQL connection\n",
    "if(conn):\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a table for New York City data\n",
    "try:\n",
    "    conn = psycopg2.connect(user = 'postgres',\n",
    "                           password = 'password',\n",
    "                           host = '127.0.0.1',\n",
    "                           port = '5432',\n",
    "                           database = 'citibike_data')\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Some data types have been amended below to account for all data in the csv (i.e. blank cells)\n",
    "    create_table_query = '''CREATE TABLE new_york_city(\n",
    "                            trip_duration INT,\n",
    "                            start_time TIMESTAMP,\n",
    "                            stop_time TIMESTAMP,\n",
    "                            start_station_id INT,\n",
    "                            start_station_name TEXT,\n",
    "                            start_station_latitude FLOAT,\n",
    "                            start_station_longitude FLOAT,\n",
    "                            end_station_id INT,\n",
    "                            end_station_name TEXT,\n",
    "                            end_station_latitude FLOAT,\n",
    "                            end_station_longitude FLOAT,\n",
    "                            bike_id INT,\n",
    "                            user_type TEXT,\n",
    "                            birth_year TEXT,\n",
    "                            gender INT\n",
    "                            ); '''\n",
    "    \n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    print(\"Table created successfully in PostgreSQL\")\n",
    "\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error while creating PostgreSQL table:\", error)\n",
    "finally:\n",
    "    # closing database connection\n",
    "    if (conn):\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating the NYC table\n",
    "try:\n",
    "    conn = psycopg2.connect(user = 'postgres',\n",
    "                           password = 'password',\n",
    "                           host = '127.0.0.1',\n",
    "                           port = '5432',\n",
    "                           database = 'citibike_data')\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    with open('C:/Users/Hui/Desktop/Graduate_Project/CitiBike/data/2013/ny_trip_data_2013.csv', 'r') as data:\n",
    "        next(data) # skip the header row\n",
    "        cursor.copy_from(data, 'new_york_city', sep=',')\n",
    "        \n",
    "        conn.commit()\n",
    "        \n",
    "        print(\"Table updated successfully in PostgreSQL \")\n",
    "        \n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print (\"Error while updating PostgreSQL table:\", error)\n",
    "    \n",
    "finally:\n",
    "    if(conn):\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsettled problem:  \n",
    "- separate the data by years\n",
    "- improve pd.read() function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webmap",
   "language": "python",
   "name": "webmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
